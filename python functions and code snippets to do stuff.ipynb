{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb68f6e",
   "metadata": {},
   "source": [
    "#### 1. `numeric_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_columns(df):\n",
    "    '''\n",
    "    Return a list of columns those have numeric values.\n",
    "\n",
    "    '''\n",
    "    return df.select_dtypes(include='number').columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a20230",
   "metadata": {},
   "source": [
    "#### 2. Add new rows to an existing DataFrame `df`\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(columns=['col1', 'col2',..., coln])\n",
    "df.loc[len(df.index)] = [col1_val, col2_val, ..., col_valn]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d16d2bcc",
   "metadata": {},
   "source": [
    "#### 3. Pandas DataFrame to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f869812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def pandas_to_spark(pandas_df):\n",
    "    # Create equivalent PySpark data types dictionary\n",
    "    equivalent_types = {\n",
    "        'datetime64[ns]': TimestampType(),\n",
    "        'int64': LongType(),\n",
    "        'int32': IntegerType(),\n",
    "        'float64': DoubleType(),\n",
    "        'float32': FloatType()\n",
    "    }\n",
    "\n",
    "    # Create StructField based on the column type\n",
    "    def define_structure(column, format_type):\n",
    "        spark_type = equivalent_types.get(format_type, StringType())\n",
    "        return StructField(column, spark_type)\n",
    "\n",
    "    # Create StructType for the PySpark DataFrame schema\n",
    "    struct_list = [define_structure(column, typ) for column, typ in pandas_df.dtypes]\n",
    "    p_schema = StructType(struct_list)\n",
    "\n",
    "    # Convert Pandas DataFrame to PySpark DataFrame\n",
    "    return spark.createDataFrame(pandas_df, p_schema)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3651ac8",
   "metadata": {},
   "source": [
    "#### 4. Get week number form a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5154b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def fn_week_number(date):\n",
    "    def is_leap_year(year):\n",
    "        return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "    \n",
    "    day_of_month = date.day()\n",
    "    days_before_month = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
    "    day_of_year = day_of_month + days_before_month[date.month - 1] + (1 if is_leap_year(date.year) and date.month > 2 else 0)\n",
    "    adjustment = (date.weekday() - day_of_year % 7 + 7) % 7\n",
    "    return (day_of_year + adjustment) // 7 + 1\n",
    "\n",
    "date = dt.date(2020, 12, 25)\n",
    "week_number = fn_week_number(date)\n",
    "print(week_number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73019cdc",
   "metadata": {},
   "source": [
    "#### 5. Write to delta\n",
    "Write the spark DataFrame as a delta table.\n",
    "\n",
    "```python\n",
    "df.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\",True).save(delta_output_path)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2bd673",
   "metadata": {},
   "source": [
    "#### 6. Remove duplicated columns from a pandas DataFrame while retaining one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35500587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def drop_duplicate_cols(df_w_duplicates):\n",
    "    # Find duplicate columns\n",
    "    duplicate_cols = [key for key, count in Counter(df_w_duplicates.columns).items() if count > 1]\n",
    "    print('Number of duplicate columns before dropping: {}'.format(len(duplicate_cols)))\n",
    "\n",
    "    # Create modified column names\n",
    "    modified_cols = []\n",
    "    seen = set()\n",
    "    for col in df_w_duplicates.columns:\n",
    "        modified_col = col if col not in seen else '{}_dup'.format(col)\n",
    "        modified_cols.append(modified_col)\n",
    "        seen.add(col)\n",
    "\n",
    "    # Create a DataFrame with modified column names and drop duplicate columns\n",
    "    drop_cols = [col for col in modified_cols if col.endswith('_dup')]\n",
    "    drop_df = df_w_duplicates.copy()\n",
    "    drop_df.columns = modified_cols\n",
    "    drop_df = drop_df.loc[:, ~drop_df.columns.isin(drop_cols)]\n",
    "\n",
    "    print('Number of duplicate columns after dropping: {}'.format(len(duplicate_cols(drop_df))))\n",
    "    return drop_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4649189c",
   "metadata": {},
   "source": [
    "#### 7. Supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Globally, for the whole notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Option 1: Ignore specific warnings (Ex- FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Option 2: Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Supress warnings for a specific block of code\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    # Warning-causing lines of code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5edd9dd0-7220-4906-aa77-db6ad9a1246c",
   "metadata": {},
   "source": [
    "#### 8. String to Dict\n",
    "\n",
    "Convert a string in dictionary format to proper python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070204e-e3e9-4177-8acb-66d5b5fa3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "    \n",
    "ast.literal_eval(\"{'muffin' : 'lolz', 'foo' : 'kitty'}\")\n",
    "\n",
    "# This can be applied to pandas df\n",
    "df['string_col'].apply(lambda x: ast.literal_eval(x) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47b95aa7",
   "metadata": {},
   "source": [
    "#### 9. Reverse Dictionary\n",
    "\n",
    "```py3\n",
    "revresed = \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
